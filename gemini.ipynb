{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7388c572-e27c-4c8a-bbd1-bb8d78139995",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\santhoshs.s\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     C:\\Users\\santhoshs.s\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "import PyPDF2\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import csv\n",
    "import os\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('averaged_perceptron_tagger_eng')\n",
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    \"\"\"\n",
    "    Extracts text from a PDF document.\n",
    "\n",
    "    Args:\n",
    "        pdf_path (str): Path to the PDF file.\n",
    "\n",
    "    Returns:\n",
    "        str: Extracted text content.\n",
    "    \"\"\"\n",
    "    with open(pdf_path, 'rb') as pdf_file:\n",
    "        pdf_reader = PyPDF2.PdfReader(pdf_file)\n",
    "        text = ''\n",
    "        for page_num in range(len(pdf_reader.pages)):\n",
    "            page = pdf_reader.pages[page_num]\n",
    "            text += page.extract_text()\n",
    "        return text\n",
    "\n",
    "def extract_name(text):\n",
    "    \"\"\"\n",
    "    Attempts to extract a name from the provided text using regular expressions and NER.\n",
    "\n",
    "    Args:\n",
    "        text (str): Text content to search for names.\n",
    "\n",
    "    Returns:\n",
    "        str: Extracted name (if found), or an empty string.\n",
    "    \"\"\"\n",
    "    # Try regular expressions first\n",
    "    name_patterns = [r\"[A-Z][a-z]+ [A-Z][a-z]+\",  # Two words with capital letters\n",
    "                   r\"[A-Z][a-z]+-\\w+\"]  # Hyphenated names\n",
    "    for pattern in name_patterns:\n",
    "        match = re.search(pattern, text)\n",
    "        if match:\n",
    "            return match.group()\n",
    "\n",
    "    # If regular expressions fail, try NER\n",
    "    try:\n",
    "        tokens = word_tokenize(text)\n",
    "        tagged_text = nltk.pos_tag(tokens)\n",
    "        for word, tag in tagged_text:\n",
    "            if tag == 'NNP':  # Proper noun\n",
    "                return word\n",
    "    except LookupError:  # NLTK data might not be downloaded\n",
    "        print(\"NLTK data not downloaded. Install NLTK and run 'nltk.download()' to download required resources.\")\n",
    "\n",
    "    return \"\"\n",
    "\n",
    "def extract_contact_details(text):\n",
    "    \"\"\"\n",
    "    Attempts to extract email, phone number, and address using regular expressions.\n",
    "\n",
    "    Args:\n",
    "        text (str): Text content to search for contact information.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing extracted email, phone number, and address (if found).\n",
    "    \"\"\"\n",
    "    email_pattern = r\"[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}\"\n",
    "    phone_pattern = r\"[0-9]{3}-[0-9]{3}-[0-9]{4}\"  # US-style phone number (modify for other formats)\n",
    "    address_pattern = r\"[0-9]+\\s?[a-zA-Z]+(?:\\s[a-zA-Z]+)?\\s+(?:[A-Z][a-z]+\\s?)*,\\s?[A-Z]{2}\\s+\\d{5}(?:-\\d{4})?\"\n",
    "\n",
    "    matches = {}\n",
    "    matches[\"email\"] = re.search(email_pattern, text)\n",
    "    if matches[\"email\"]:\n",
    "        matches[\"email\"] = matches[\"email\"].group()\n",
    "\n",
    "    matches[\"phone_number\"] = re.search(phone_pattern, text)\n",
    "    if matches[\"phone_number\"]:\n",
    "        matches[\"phone_number\"] = matches[\"phone_number\"].group()\n",
    "\n",
    "    matches[\"address\"] = re.search(address_pattern, text)\n",
    "    if matches[\"address\"]:\n",
    "        matches[\"address\"] = matches[\"address\"].group()\n",
    "\n",
    "    return matches\n",
    "\n",
    "def extract_skills_from_text(text):\n",
    "    \"\"\"\n",
    "    Attempts to extract skills using NLTK and Part-of-Speech tagging.\n",
    "\n",
    "    Args:\n",
    "        text (str): Text content to search for skills.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of extracted skills.\n",
    "    \"\"\"\n",
    "    skills = []\n",
    "    tokens = word_tokenize(text)\n",
    "    tagged_text = nltk.pos_tag(tokens)\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "\n",
    "    for word, tag in tagged_text:\n",
    "        if tag == 'NN' or tag == 'VB' and word.lower() not in stop_words:\n",
    "            skills.append(word)\n",
    "\n",
    "    return skills\n",
    "\n",
    "def extract_experience_from_text(text):\n",
    "    \"\"\"\n",
    "    Attempts to extract experience details using regular expressions.\n",
    "\n",
    "    Args:\n",
    "        text (str): Text content to search for experience details.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of dictionaries, each containing experience details (job title, company, start date, end date).\n",
    "    \"\"\"\n",
    "    experience_pattern = r\"([A-Z][a-z]+(?:\\s[A-Z][a-z]+)?) at ([A-Z][a-z]+(?:\\s[A-Z][a-z]+)?) from ([\\d/]+) to ([\\d/]+)\"\n",
    "    matches = re.findall(experience_pattern, text)\n",
    "    experience_list = []\n",
    "    for match in matches:\n",
    "        experience = {\n",
    "            \"job_title\": match[0],\n",
    "            \"company\": match[1],\n",
    "            \"start_date\": match[2],\n",
    "            \"end_date\": match[3]\n",
    "        }\n",
    "        experience_list.append(experience)\n",
    "    return experience_list\n",
    "\n",
    "def extract_education_from_text(text):\n",
    "    \"\"\"\n",
    "    Attempts to extract education details using regular expressions.\n",
    "\n",
    "    Args:\n",
    "        text (str): Text content to search for education details.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of dictionaries, each containing education details (degree, field, institution, year).\n",
    "    \"\"\"\n",
    "    education_pattern = r\"([A-Z][a-z]+(?:\\s[A-Z][a-z]+)?) in ([A-Z][a-z]+(?:\\s[A-Z][a-z]+)?) from ([A-Z][a-z]+(?:\\s[A-Z][a-z]+)?) in ([\\d]{4})\"\n",
    "    matches = re.findall(education_pattern, text)\n",
    "    education_list = []\n",
    "    for match in matches:\n",
    "        education = {\n",
    "            \"degree\": match[0],\n",
    "            \"field\": match[1],\n",
    "            \"institution\": match[2],\n",
    "            \"year\": match[3]\n",
    "        }\n",
    "        education_list.append(education)\n",
    "    return education_list\n",
    "\n",
    "def extract_information_from_resumes(resume_folder, csv_file):\n",
    "    \"\"\"\n",
    "    Extracts information from PDF resumes in a specified folder and saves it to a CSV file.\n",
    "\n",
    "    Args:\n",
    "        resume_folder (str): Path to the folder containing resumes.\n",
    "        csv_file (str): Path to the CSV file where extracted information will be saved.\n",
    "    \"\"\"\n",
    "    header = [\"name\", \"email\", \"phone_number\", \"address\", \"skills\", \"experience\", \"education\"]\n",
    "    with open(csv_file, 'w', newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerow(header)\n",
    "        for filename in os.listdir(resume_folder):\n",
    "            if filename.endswith('.pdf'):\n",
    "                pdf_path = os.path.join(resume_folder, filename)\n",
    "                text = extract_text_from_pdf(pdf_path)\n",
    "                name = extract_name(text)\n",
    "                contact_details = extract_contact_details(text)\n",
    "                skills = extract_skills_from_text(text)\n",
    "                experience = extract_experience_from_text(text)\n",
    "                education = extract_education_from_text(text)\n",
    "                row = [name, contact_details[\"email\"], contact_details[\"phone_number\"], contact_details[\"address\"], skills, experience, education]\n",
    "                writer.writerow(row)\n",
    "\n",
    "# Example usage\n",
    "resume_folder = \"C:\\\\Users\\\\santhoshs.s\\\\jupyter\\\\resumes\\\\data\\\\data\\\\BPO\\\\bb\"\n",
    "csv_file = \"resume_data.csv\"\n",
    "extract_information_from_resumes(resume_folder, csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e85bc23f-7432-4972-bdaf-8d4e202710cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to output3.csv\n",
      "Data saved to output3.csv\n"
     ]
    }
   ],
   "source": [
    "import fitz  \n",
    "import re\n",
    "import pandas as pd\n",
    "import os\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "import PyPDF2\n",
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    with fitz.open(pdf_path) as doc:\n",
    "        text = \"\"\n",
    "        for page in doc:\n",
    "            text += page.get_text()\n",
    "    return text.lower()  \n",
    "\n",
    "def extract_name(text):\n",
    "    name_patterns = [\n",
    "        r\"[A-Z][a-z]+ [A-Z][a-z]+\",  # Matches names like \"John Doe\"\n",
    "        r\"[A-Z][a-z]+-\\w+\",           # Matches hyphenated names like \"Anne-Marie\"\n",
    "        r\"\\b[A-Z]+(?: [A-Z]+)* ?[A-Z]?\\b\"  # Matches fully capitalized names like \"HARRISH KALYAN V\"\n",
    "    ]\n",
    "\n",
    "    for pattern in name_patterns:\n",
    "        match = re.search(pattern, text, re.IGNORECASE)  \n",
    "        if match:\n",
    "            return match.group()\n",
    "            \n",
    "    try:\n",
    "        tokens = word_tokenize(text)\n",
    "        tagged_text = nltk.pos_tag(tokens)\n",
    "        for word, tag in tagged_text:\n",
    "            if tag == 'NNP': \n",
    "                return word\n",
    "    except LookupError:\n",
    "        print(\"NLTK data not downloaded. Install NLTK and run 'nltk.download()' to download required resources.\")\n",
    "\n",
    "    return \"Not Found\"\n",
    "\n",
    "\n",
    "def extract_profile_summary(text):\n",
    "    keywords = [\n",
    "        \"summary\", \"profile\", \"objective\", \"professional summary\",\n",
    "        \"career summary\", \"executive summary\", \"personal summary\",\n",
    "        \"summary of qualifications\", \"overview\", \"Profile\"\n",
    "    ]\n",
    "    \n",
    "    lines = text.splitlines()\n",
    "    summary_start = None\n",
    "\n",
    "    keyword_patterns = [re.compile(r'\\s*'.join(list(keyword.lower()))) for keyword in keywords]\n",
    "\n",
    "    for pattern in keyword_patterns:\n",
    "        for idx, line in enumerate(lines):\n",
    "            if pattern.search(line.lower()):  \n",
    "                summary_start = idx\n",
    "                break\n",
    "        if summary_start is not None:\n",
    "            break\n",
    "\n",
    "    if summary_start is not None:\n",
    "        extracted_lines = []\n",
    "        \n",
    "        for i in range(summary_start + 1, len(lines)):\n",
    "            line = lines[i].strip()\n",
    "\n",
    "            if line == \"\" or line.startswith(\"*\") or line.startswith(\"#\"):\n",
    "                continue\n",
    "            if line.isupper():\n",
    "                break\n",
    "            \n",
    "            extracted_lines.append(line)\n",
    "\n",
    "        summary_result = \"\\n\".join(extracted_lines).strip()\n",
    "        return summary_result if summary_result else \"Not Found\"\n",
    "    \n",
    "    return \"Not Found\"\n",
    "\n",
    "# Function to extract email address\n",
    "def extract_email(text):\n",
    "    email_pattern = r'[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}'\n",
    "    match = re.search(email_pattern, text)\n",
    "    return match.group(0) if match else \"Not Found\"\n",
    "\n",
    "# Function to extract the phone number\n",
    "def extract_phone_number(text):\n",
    "    phone_pattern = r'\\b(?:\\+?(\\d{1,3}))?[-. ()]*(\\d{3})[-. )]*(\\d{3})[-. ]*(\\d{4})\\b'\n",
    "    match = re.search(phone_pattern, text)\n",
    "    \n",
    "    if match:\n",
    "        raw_number = match.group(0)\n",
    "        clean_number = re.sub(r'\\D', '', raw_number) \n",
    "        return clean_number\n",
    "    \n",
    "    return \"Not Found\"\n",
    "\n",
    "# Function to extract address\n",
    "def extract_address(text):\n",
    "    address_keywords = ['address', 'street', 'city', 'state', 'zip', 'postal']\n",
    "    lines = text.split('\\n')\n",
    "    for line in lines:\n",
    "        if any(keyword in line.lower() for keyword in address_keywords):\n",
    "            return line.strip()\n",
    "    return \"Not Found\"\n",
    "\n",
    "# Function to extract links along with associated text from a PDF file\n",
    "def extract_links(pdf_path):\n",
    "    links_with_text = []\n",
    "    \n",
    "    with open(pdf_path, 'rb') as pdf_file:\n",
    "        pdf_reader = PyPDF2.PdfReader(pdf_file)\n",
    "\n",
    "        for page_num in range(len(pdf_reader.pages)):\n",
    "            page = pdf_reader.pages[page_num]\n",
    "\n",
    "            if '/Annots' in page:\n",
    "                annotations = page['/Annots']\n",
    "                for annotation in annotations:\n",
    "                    annotation_object = annotation.get_object()\n",
    "                    if '/A' in annotation_object and '/URI' in annotation_object['/A']:\n",
    "                        link = annotation_object['/A']['/URI']\n",
    "\n",
    "                        links_with_text.append(link)\n",
    "    # Join the links, placing each on a new line\n",
    "    return '\\n'.join(links_with_text) if links_with_text else \"Not Found\"\n",
    "\n",
    "def extract_skills(text):\n",
    "    skills_keywords = [\n",
    "        \"python\", \"java\", \"c++\", \"sql\", \"javascript\", \"html\", \"css\",\n",
    "        \"data analysis\", \"machine learning\", \"deep learning\", \"project management\",\n",
    "        \"excel\", \"communication\", \"teamwork\", \"problem solving\", \"time management\",\n",
    "        \"leadership\", \"adobe photoshop\", \"graphic design\", \"cloud computing\",\n",
    "        \"aws\", \"azure\", \"docker\", \"kubernetes\", \"linux\", \"windows\",\n",
    "        \"networking\", \"digital marketing\", \"seo\", \"content writing\", \"sql\", \n",
    "        \"nosql\", \"data visualization\", \"power bi\", \"tableau\", \"salesforce\",\n",
    "        \"financial analysis\", \"r programming\", \"pandas\", \"numpy\", \"tensorflow\", \"keras\",\n",
    "        \"project planning\", \"agile\", \"scrum\", \"big data\", \"hadoop\", \"spark\", \"Food preparation\",\n",
    "        \"Kitchen maintenance\", \"Kitchen equipment\", \"operation\", \"Food sanitation\"\n",
    "\n",
    "    ]\n",
    "    \n",
    "    text_lower = text.lower()\n",
    "\n",
    "    found_skills = set()\n",
    "\n",
    "    for skill in skills_keywords:\n",
    "        pattern = r'\\b' + re.escape(skill.lower()) + r'\\b'\n",
    "        if re.search(pattern, text_lower):\n",
    "            found_skills.add(skill)\n",
    "\n",
    "    return sorted(found_skills) if found_skills else \"Not Found\"\n",
    "\n",
    "import re\n",
    "\n",
    "def extract_experience(text):\n",
    "    # List of job roles to search for\n",
    "    job_roles = [\n",
    "        \"Staff Accountant\", \"Bookkeeper\", \"Accounts Payable Specialist\", \"Accounts Receivable Specialist\",\n",
    "        \"Payroll Specialist\", \"General Ledger Accountant\", \"Cash Applications Specialist\", \"Fixed Assets Accountant\",\n",
    "        \"Revenue Recognition Specialist\", \"Financial Reporting Analyst\", \"Financial Accountant\", \"Cost Accountant\",\n",
    "        \"Tax Accountant\", \"Forensic Accountant\", \"Financial Reporting Manager\", \"Financial Analyst\", \"Budget Analyst\",\n",
    "        \"Internal Auditor\", \"Compliance Officer\", \"Risk Analyst\", \"Controller\", \"Financial Controller\",\n",
    "        \"Corporate Controller\", \"Divisional Controller\", \"Financial Planning and Analysis Manager\", \"Business Analyst\",\n",
    "        \"Management Accountant\", \"Cost Control Analyst\", \"Profitability Analyst\", \"Performance Analyst\",\n",
    "        \"Auditing Manager\", \"Tax Manager\", \"International Accountant\", \"Government Accountant\", \"Non-profit Accountant\",\n",
    "        \"Healthcare Accountant\", \"Manufacturing Accountant\", \"Retail Accountant\", \"Construction Accountant\",\n",
    "        \"Information Technology Accountant\", \"Real Estate Accountant\", \"Mergers and Acquisitions Accountant\",\n",
    "        \"Fraud Examiner\", \"Forensic Auditor\", \"Valuation Specialist\", \"Financial Advisor\", \"Financial Consultant\",\n",
    "        \"CFO (Chief Financial Officer)\", \"Treasurer\", \"Financial Operations Manager\",\n",
    "        # Additional job roles created for enhancement\n",
    "        \"Accounts Manager\", \"Finance Director\", \"Revenue Analyst\", \"Cash Management Specialist\",\n",
    "        \"Business Development Manager\", \"Risk Management Consultant\", \"Tax Compliance Analyst\",\n",
    "        \"Investment Analyst\", \"Corporate Finance Manager\", \"Cost Analyst\", \"Budget Officer\",\n",
    "        \"Financial Systems Analyst\", \"Procurement Analyst\", \"Loan Officer\", \"Equity Analyst\",\n",
    "        \"Financial Planning Manager\", \"Audit Associate\", \"Financial Operations Analyst\", \"Risk Management Analyst\",\n",
    "        \"Tax Associate\", \"Compliance Analyst\", \"Financial Reporting Officer\", \"Strategic Finance Analyst\",\n",
    "        \"Credit Analyst\", \"Accounts Supervisor\", \"Payment Analyst\", \"Financial Risk Manager\",\n",
    "        \"Real Estate Financial Analyst\", \"Insurance Accountant\", \"Treasury Analyst\", \"Securities Analyst\",\n",
    "        \"Fixed Income Analyst\", \"Equity Research Analyst\", \"Actuarial Analyst\", \"Real Estate Investment Analyst\",\n",
    "        \"Performance Measurement Analyst\", \"Corporate Treasury Manager\", \"Investment Banking Analyst\",\n",
    "        \"Project Finance Analyst\", \"Financial Product Manager\", \"Operations Accountant\", \"Compliance Manager\",\n",
    "        \"Cost Estimator\", \"Business Intelligence Analyst\"\n",
    "    ]\n",
    "\n",
    "    # Define patterns for dates\n",
    "    date_patterns = [\n",
    "        r\"\\b(19[9]\\d|20[0-2]\\d)\\b\",  # Years from 1990 to 2029\n",
    "        r\"\\b(19[9]\\d|20[0-2]\\d)[-–](19[9]\\d|20[0-2]\\d)\\b\",  # Year ranges like \"2020-2022\"\n",
    "        r\"\\b(19[9]\\d|20[0-2]\\d)[-–](Present|present)\\b\",  # Year ranges like \"2021-Present\"\n",
    "        r\"\\b(?:Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)[a-z]* \\d{4}\\b\",  # Month Year\n",
    "        r\"\\b(?:Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)[a-z]* \\d{4}[-–] (?:Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)[a-z]* \\d{4}\\b\"  # Month Year - Month Year\n",
    "    ]\n",
    "\n",
    "    # Combine all date patterns into a single regex pattern\n",
    "    date_pattern = re.compile(\"|\".join(date_patterns), re.IGNORECASE)\n",
    "\n",
    "    # Split the text into lines for processing\n",
    "    lines = text.splitlines()\n",
    "\n",
    "    # Storage for job entries\n",
    "    experience_list = []\n",
    "    current_experience = {}\n",
    "\n",
    "    # Iterate through lines to extract experience data\n",
    "    for i, line in enumerate(lines):\n",
    "        line = line.strip()\n",
    "\n",
    "        # Skip empty lines\n",
    "        if not line:\n",
    "            continue\n",
    "\n",
    "        # Check for job roles mentioned in the line\n",
    "        for job in job_roles:\n",
    "            if job.lower() in line.lower():\n",
    "                # If a job title is found, initiate job extraction\n",
    "                current_experience[\"Job Title\"] = job\n",
    "                \n",
    "                # Look for dates in the line\n",
    "                date_match = date_pattern.search(line)\n",
    "                if date_match:\n",
    "                    current_experience[\"Dates\"] = date_match.group()\n",
    "\n",
    "                # Look for the company name (assumes it's mentioned after 'at' or similar)\n",
    "                company_match = re.search(r\"(?:at|for|with) ([A-Z][a-zA-Z]+(?: [A-Z][a-zA-Z]+)*)\", line, re.IGNORECASE)\n",
    "                if company_match:\n",
    "                    current_experience[\"Company\"] = company_match.group(1)\n",
    "                \n",
    "                # Look for the place (assumes it's mentioned after 'in' or 'at')\n",
    "                place_match = re.search(r\"(?:in|at) ([A-Z][a-zA-Z]+(?: [A-Z][a-zA-Z]+)*)\", line, re.IGNORECASE)\n",
    "                if place_match:\n",
    "                    current_experience[\"Place\"] = place_match.group(1)\n",
    "                \n",
    "                # Add to the experience list if we have essential details\n",
    "                if current_experience.get(\"Company\") and current_experience.get(\"Job Title\") and current_experience.get(\"Dates\"):\n",
    "                    company = current_experience.get(\"Company\", \"\")\n",
    "                    role = current_experience.get(\"Job Title\", \"\")\n",
    "                    dates = current_experience.get(\"Dates\", \"\")\n",
    "                    place = current_experience.get(\"Place\", \"\")\n",
    "                    experience_entry = f\"{company}-{role}-{dates}-{place}\"\n",
    "                    experience_list.append(experience_entry)\n",
    "                    current_experience = {}  # Reset for the next job\n",
    "\n",
    "                break  # Stop checking further job roles in this line if one is found\n",
    "\n",
    "        # Look for dates in the line if no job roles are found\n",
    "        if not current_experience and date_pattern.search(line):\n",
    "            # Handle cases where we need to find company and place based on earlier logic\n",
    "            current_experience[\"Dates\"] = date_pattern.search(line).group()\n",
    "\n",
    "            # Look for job titles and companies around this line\n",
    "            job_description = [line]\n",
    "\n",
    "            # Check the next 2 lines for more job details (job title, company)\n",
    "            for next_line in lines[i+1:i+3]:\n",
    "                next_line = next_line.strip()\n",
    "                if next_line:\n",
    "                    job_description.append(next_line)\n",
    "\n",
    "            combined_description = \" \".join(job_description)\n",
    "\n",
    "            # Extract job title based on capitalized words pattern\n",
    "            job_title_match = re.search(r\"([A-Z][a-zA-Z]+(?: [A-Z][a-zA-Z]+)*)\", combined_description)\n",
    "            if job_title_match:\n",
    "                current_experience[\"Job Title\"] = job_title_match.group()\n",
    "\n",
    "            # Extract company name based on context\n",
    "            company_match = re.search(r\"(?:at|for|with) ([A-Z][a-zA-Z]+(?: [A-Z][a-zA-Z]+)*)\", combined_description, re.IGNORECASE)\n",
    "            if company_match:\n",
    "                current_experience[\"Company\"] = company_match.group(1)\n",
    "\n",
    "            # Extract place\n",
    "            place_match = re.search(r\"(?:in|at) ([A-Z][a-zA-Z]+(?: [A-Z][a-zA-Z]+)*)\", combined_description, re.IGNORECASE)\n",
    "            if place_match:\n",
    "                current_experience[\"Place\"] = place_match.group(1)\n",
    "\n",
    "    # Append the last found experience if it exists\n",
    "    if current_experience:\n",
    "        company = current_experience.get(\"Company\", \"\")\n",
    "        role = current_experience.get(\"Job Title\", \"\")\n",
    "        dates = current_experience.get(\"Dates\", \"\")\n",
    "        place = current_experience.get(\"Place\", \"\")\n",
    "        experience_entry = f\"{company}-{role}-{dates}-{place}\"\n",
    "        experience_list.append(experience_entry)\n",
    "\n",
    "    # Filter out any experience entries with dates before 1990\n",
    "    experience_list = [entry for entry in experience_list if not re.search(r\"\\b(19[0-8]\\d)\\b\", entry)]\n",
    "\n",
    "    # Return the extracted experience data or 'Not Found' if nothing was found\n",
    "    return experience_list if experience_list else [\"Not Found\"]\n",
    "\n",
    "\n",
    "\n",
    "# Function to extract education details\n",
    "def extract_education(text):\n",
    "    education_list = []\n",
    "    education_keywords = [\"education\", \"academic background\"]\n",
    "    for keyword in education_keywords:\n",
    "        education_start = text.find(keyword)\n",
    "        if education_start != -1:\n",
    "            lines = text.splitlines()[education_start:]  \n",
    "            for line in lines:\n",
    "                if line.strip() == \"\":\n",
    "                    continue  \n",
    "                university_match = re.search(r\"[A-Z][a-z]+(?:\\s[A-Z][a-z]+)?\", line, re.IGNORECASE)\n",
    "                if university_match:\n",
    "                    university = university_match.group()\n",
    "                    degree_match = re.search(r\"[A-Z][a-z]+(?:\\s[A-Z][a-z]+)?\", line, re.IGNORECASE)\n",
    "                    degree = degree_match.group() if degree_match else \"\"\n",
    "                    year_match = re.search(r\"\\d{4}\", line)\n",
    "                    year = year_match.group() if year_match else \"\"\n",
    "                    education_list.append({\n",
    "                        \"University\": university,\n",
    "                        \"Degree\": degree,\n",
    "                        \"Year\": year\n",
    "                    })\n",
    "            break\n",
    "    return education_list\n",
    "\n",
    "# Function to extract languages\n",
    "def extract_languages(text):\n",
    "    language_keywords = [\"languages\", \"skills\", \"proficiency\"]\n",
    "    for keyword in language_keywords:\n",
    "        language_start = text.find(keyword)\n",
    "        if language_start != -1:\n",
    "            lines = text.splitlines()[language_start:]\n",
    "            languages = []\n",
    "            for line in lines:\n",
    "                if line.strip() == \"\":\n",
    "                    continue\n",
    "                language_match = re.search(r\"[A-Z][a-z]+(?:\\s[A-Z][a-z]+)?\", line, re.IGNORECASE)\n",
    "                if language_match:\n",
    "                    languages.append(language_match.group())\n",
    "            return languages\n",
    "    return []\n",
    "\n",
    "# Function to extract certificates\n",
    "def extract_certificates(text):\n",
    "    certificate_keywords = [\"certifications\", \"accreditations\"]\n",
    "    for keyword in certificate_keywords:\n",
    "        certificate_start = text.find(keyword)\n",
    "        if certificate_start != -1:\n",
    "            lines = text.splitlines()[certificate_start:]\n",
    "            certificates = []\n",
    "            for line in lines:\n",
    "                if line.strip() == \"\":\n",
    "                    continue\n",
    "                certificate_match = re.search(r\"[A-Z][a-z]+(?:\\s[A-Z][a-z]+)?\", line, re.IGNORECASE)\n",
    "                if certificate_match:\n",
    "                    certificates.append(certificate_match.group())\n",
    "            return certificates\n",
    "    return []\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Function to process all PDFs in a folder and save the extracted info in a CSV\n",
    "def process_resumes(folder_path, output_csv_path):\n",
    "    data = []\n",
    "\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith('.pdf'):\n",
    "            pdf_path = os.path.join(folder_path, filename)\n",
    "            text = extract_text_from_pdf(pdf_path)\n",
    "\n",
    "            name = extract_name(text)\n",
    "            profile_summary = extract_profile_summary(text)\n",
    "            email = extract_email(text)\n",
    "            phone = extract_phone_number(text)\n",
    "            address = extract_address(text)\n",
    "            links = extract_links(pdf_path)\n",
    "            experience = extract_experience(text)\n",
    "            education = extract_education(text)\n",
    "            languages = extract_languages(text)\n",
    "            certificates = extract_certificates(text)\n",
    "            skills = extract_skills(text)\n",
    "\n",
    "            data.append({\n",
    "                'File Name': filename,\n",
    "                'Name': name,\n",
    "                'Profile Summary': profile_summary,\n",
    "                'Email': email,\n",
    "                'Phone': phone,\n",
    "                'Address': address,\n",
    "                'Links': links,\n",
    "                'Skills': skills,\n",
    "                'Experience': experience,\n",
    "                'Education': education,\n",
    "                'Languages': languages,\n",
    "                'Certificates': certificates,  \n",
    "            })\n",
    "\n",
    "    # Create a DataFrame from the collected data\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    # Clear previous data in the CSV file\n",
    "    if os.path.exists(output_csv_path):\n",
    "        os.remove(output_csv_path)  # Remove the existing file\n",
    "\n",
    "    # Save the new data to the CSV file\n",
    "    df.to_csv(output_csv_path, index=False)\n",
    "    print(f'Data saved to {output_csv_path}')\n",
    "\n",
    "\n",
    "    # Create a DataFrame and save it to a CSV file\n",
    "    df = pd.DataFrame(data)\n",
    "    df.to_csv(output_csv_path, index=False)\n",
    "    print(f'Data saved to {output_csv_path}')\n",
    "\n",
    "process_resumes('C:\\\\Users\\\\santhoshs.s\\\\jupyter\\\\resumes\\\\data\\\\data\\\\BPO\\\\bb', 'output3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff038128-fe6e-46dd-903f-5c75f1254356",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
