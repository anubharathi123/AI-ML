{"cells":[{"cell_type":"code","source":["pip install pdfplumber"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kJ4oCQE7IZZl","executionInfo":{"status":"ok","timestamp":1729162817886,"user_tz":-330,"elapsed":6140,"user":{"displayName":"ds225229139 M.Sc. Data Science","userId":"17204601607049161067"}},"outputId":"fdd2d57b-d3f5-4c2b-efaa-94f43b90863a"},"id":"kJ4oCQE7IZZl","execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting pdfplumber\n","  Downloading pdfplumber-0.11.4-py3-none-any.whl.metadata (41 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/42.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.0/42.0 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting pdfminer.six==20231228 (from pdfplumber)\n","  Downloading pdfminer.six-20231228-py3-none-any.whl.metadata (4.2 kB)\n","Requirement already satisfied: Pillow>=9.1 in /usr/local/lib/python3.10/dist-packages (from pdfplumber) (10.4.0)\n","Collecting pypdfium2>=4.18.0 (from pdfplumber)\n","  Downloading pypdfium2-4.30.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (48 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.5/48.5 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six==20231228->pdfplumber) (3.4.0)\n","Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six==20231228->pdfplumber) (43.0.1)\n","Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (1.17.1)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (2.22)\n","Downloading pdfplumber-0.11.4-py3-none-any.whl (59 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.2/59.2 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pdfminer.six-20231228-py3-none-any.whl (5.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m41.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pypdfium2-4.30.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m57.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: pypdfium2, pdfminer.six, pdfplumber\n","Successfully installed pdfminer.six-20231228 pdfplumber-0.11.4 pypdfium2-4.30.0\n"]}]},{"cell_type":"code","execution_count":11,"id":"55ff55d4","metadata":{"id":"55ff55d4","executionInfo":{"status":"ok","timestamp":1729162818335,"user_tz":-330,"elapsed":4,"user":{"displayName":"ds225229139 M.Sc. Data Science","userId":"17204601607049161067"}}},"outputs":[],"source":["import pdfplumber\n","import re"]},{"cell_type":"markdown","id":"06cced07","metadata":{"id":"06cced07"},"source":["### Step 1: Create the dictionary with job roles as keys and skills as values"]},{"cell_type":"code","execution_count":12,"id":"2ba6a422","metadata":{"id":"2ba6a422","executionInfo":{"status":"ok","timestamp":1729162820079,"user_tz":-330,"elapsed":8,"user":{"displayName":"ds225229139 M.Sc. Data Science","userId":"17204601607049161067"}}},"outputs":[],"source":["data = {\n","    'Software Engineer': 'Skilled in Python, machine learning, and web development with Django',\n","    'Backend Developer': 'Experience in Java, Spring Boot, and RESTful web services',\n","    'Data Analyst': 'Proficient in SQL, data analysis, and Tableau dashboards',\n","    'Frontend Developer': 'Expert in HTML, CSS, JavaScript, and React development',\n","    'AI/ML Engineer': 'Knowledge of deep learning, neural networks, and NLP tasks',\n","    'DevOps Engineer': 'Experienced in DevOps, Docker, Kubernetes, and cloud deployment'\n","}"]},{"cell_type":"code","execution_count":13,"id":"f4cf1e0b","metadata":{"id":"f4cf1e0b","executionInfo":{"status":"ok","timestamp":1729162820079,"user_tz":-330,"elapsed":5,"user":{"displayName":"ds225229139 M.Sc. Data Science","userId":"17204601607049161067"}}},"outputs":[],"source":["skill_keywords = [\n","    'python', 'java', 'machine learning', 'django', 'spring boot', 'sql',\n","    'data analysis', 'tableau', 'html', 'css', 'javascript', 'react', 'nlp',\n","    'neural networks', 'docker', 'kubernetes'\n","]"]},{"cell_type":"markdown","id":"aae52110","metadata":{"id":"aae52110"},"source":["### Step 2: Preprocess the skills (same as before)"]},{"cell_type":"code","execution_count":14,"id":"205aeede","metadata":{"id":"205aeede","executionInfo":{"status":"ok","timestamp":1729162820750,"user_tz":-330,"elapsed":5,"user":{"displayName":"ds225229139 M.Sc. Data Science","userId":"17204601607049161067"}}},"outputs":[],"source":["def preprocess_text(text):\n","    text = text.lower()\n","    text = re.sub(r'[^a-zA-Z\\s]', '', text)  # Keep only letters and spaces\n","    return set(text.split())  # Convert to a set of words"]},{"cell_type":"code","execution_count":15,"id":"bdf4eebb","metadata":{"id":"bdf4eebb","executionInfo":{"status":"ok","timestamp":1729162820751,"user_tz":-330,"elapsed":5,"user":{"displayName":"ds225229139 M.Sc. Data Science","userId":"17204601607049161067"}}},"outputs":[],"source":["preprocessed_data = {role: preprocess_text(skills) for role, skills in data.items()}"]},{"cell_type":"markdown","id":"dc418995","metadata":{"id":"dc418995"},"source":["### Step 3: Extract text from PDF resume using pdfplumber"]},{"cell_type":"code","execution_count":16,"id":"f908c0e1","metadata":{"id":"f908c0e1","executionInfo":{"status":"ok","timestamp":1729162822506,"user_tz":-330,"elapsed":7,"user":{"displayName":"ds225229139 M.Sc. Data Science","userId":"17204601607049161067"}}},"outputs":[],"source":["def extract_text_from_pdf(pdf_path):\n","    with pdfplumber.open(pdf_path) as pdf:\n","        text = \"\"\n","        for page in pdf.pages:\n","            text += page.extract_text()\n","    return text"]},{"cell_type":"markdown","id":"a48f1ea9","metadata":{"id":"a48f1ea9"},"source":["### Step 4: Extract skills from the resume text based on predefined keywords"]},{"cell_type":"code","execution_count":17,"id":"eb3cc932","metadata":{"id":"eb3cc932","executionInfo":{"status":"ok","timestamp":1729162824211,"user_tz":-330,"elapsed":2,"user":{"displayName":"ds225229139 M.Sc. Data Science","userId":"17204601607049161067"}}},"outputs":[],"source":["def extract_skills_from_resume(resume_text):\n","    resume_text = preprocess_text(resume_text)  # Preprocess the text\n","    matched_skills = [skill for skill in skill_keywords if skill in resume_text]\n","    return set(matched_skills)"]},{"cell_type":"code","execution_count":17,"id":"8874204d-0ae9-4e75-8d89-ae09bd6c0e3a","metadata":{"id":"8874204d-0ae9-4e75-8d89-ae09bd6c0e3a","executionInfo":{"status":"ok","timestamp":1729162824873,"user_tz":-330,"elapsed":6,"user":{"displayName":"ds225229139 M.Sc. Data Science","userId":"17204601607049161067"}}},"outputs":[],"source":[]},{"cell_type":"markdown","id":"ac6afc43","metadata":{"id":"ac6afc43"},"source":["### Step 5: Match extracted skills to the job roles"]},{"cell_type":"code","execution_count":18,"id":"60675f8f","metadata":{"id":"60675f8f","executionInfo":{"status":"ok","timestamp":1729162825995,"user_tz":-330,"elapsed":3,"user":{"displayName":"ds225229139 M.Sc. Data Science","userId":"17204601607049161067"}}},"outputs":[],"source":["def match_skills_to_roles(matched_skills):\n","    matching_roles = []\n","    for role, skills in preprocessed_data.items():\n","        matching_skills = matched_skills.intersection(skills)\n","        if len(matching_skills) >= 2:  # If two or more skills match, consider the role suitable\n","            matching_roles.append((role, matching_skills))\n","    return matching_roles"]},{"cell_type":"markdown","id":"8a5da0de","metadata":{"id":"8a5da0de"},"source":["### Step 6: Main logic to analyze the PDF resume"]},{"cell_type":"code","execution_count":19,"id":"8da5607f","metadata":{"id":"8da5607f","executionInfo":{"status":"ok","timestamp":1729162826664,"user_tz":-330,"elapsed":6,"user":{"displayName":"ds225229139 M.Sc. Data Science","userId":"17204601607049161067"}}},"outputs":[],"source":["def analyze_resume(pdf_path):\n","    # Extract the text from the PDF\n","    resume_text = extract_text_from_pdf(pdf_path)\n","    # Extbract skills from the resume\n","    extracted_skills = extract_skills_from_resume(resume_text)\n","\n","    # Match the extracted skills to job roles\n","    matching_roles = match_skills_to_roles(extracted_skills)\n","\n","    # Print the results\n","    if matching_roles:\n","        print(\"The resume is suitable for the following job roles based on skill matches:\")\n","        for role, matched_skills in matching_roles:\n","            print(f\"- {role}: matched skills {', '.join(matched_skills)}\")\n","    else:\n","        print(\"No suitable job roles found based on the resume's skills.\")\n"]},{"cell_type":"code","execution_count":19,"id":"1a6aaa1d-1439-46f1-a20a-0f362f482599","metadata":{"id":"1a6aaa1d-1439-46f1-a20a-0f362f482599","executionInfo":{"status":"ok","timestamp":1729162830314,"user_tz":-330,"elapsed":732,"user":{"displayName":"ds225229139 M.Sc. Data Science","userId":"17204601607049161067"}}},"outputs":[],"source":[]},{"cell_type":"code","execution_count":22,"id":"01d4de16","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"01d4de16","executionInfo":{"status":"ok","timestamp":1729163124908,"user_tz":-330,"elapsed":2556,"user":{"displayName":"ds225229139 M.Sc. Data Science","userId":"17204601607049161067"}},"outputId":"2e21c1a7-c6ca-49c8-acc6-6df01883f614"},"outputs":[{"output_type":"stream","name":"stdout","text":["Please enter the file path/content/apr_05 updated resume.pdf\n","\n","\n","The resume is suitable for the following job roles based on skill matches:\n","- Data Analyst: matched skills sql, tableau\n"]}],"source":["pdf_path = input(\"Please enter the file path\")\n","print()\n","print()\n","analyze_resume(pdf_path)"]},{"cell_type":"code","execution_count":null,"id":"2f614495-b0b6-44b5-a353-521b8b9f2a30","metadata":{"id":"2f614495-b0b6-44b5-a353-521b8b9f2a30","executionInfo":{"status":"aborted","timestamp":1729162737817,"user_tz":-330,"elapsed":10,"user":{"displayName":"ds225229139 M.Sc. Data Science","userId":"17204601607049161067"}}},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.6"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}