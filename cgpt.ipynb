{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "979b9c6f-cf9b-4391-8f3b-ef39581f699f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pymupdfNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Downloading PyMuPDF-1.24.11-cp38-abi3-win_amd64.whl.metadata (3.4 kB)\n",
      "Requirement already satisfied: pandas in c:\\users\\santhoshs.s\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\santhoshs.s\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\santhoshs.s\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\santhoshs.s\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\santhoshs.s\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\santhoshs.s\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Downloading PyMuPDF-1.24.11-cp38-abi3-win_amd64.whl (16.0 MB)\n",
      "   ---------------------------------------- 0.0/16.0 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/16.0 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 1.6/16.0 MB 6.0 MB/s eta 0:00:03\n",
      "   ------------- -------------------------- 5.2/16.0 MB 12.2 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 5.2/16.0 MB 12.2 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 7.9/16.0 MB 8.5 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 10.2/16.0 MB 9.1 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 12.6/16.0 MB 9.6 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 13.9/16.0 MB 8.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  15.7/16.0 MB 9.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 16.0/16.0 MB 8.7 MB/s eta 0:00:00\n",
      "Installing collected packages: pymupdf\n",
      "Successfully installed pymupdf-1.24.11\n"
     ]
    }
   ],
   "source": [
    "pip install pymupdf pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c88ba0e-e40c-47de-a1d9-e832406f7f71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to output.csv\n"
     ]
    }
   ],
   "source": [
    "import fitz  # PyMuPDF for reading PDFs\n",
    "import re\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Function to extract text from PDF file\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    with fitz.open(pdf_path) as doc:\n",
    "        text = \"\"\n",
    "        for page in doc:\n",
    "            text += page.get_text()\n",
    "    return text\n",
    "\n",
    "# Function to extract the candidate's name\n",
    "def extract_name(text):\n",
    "    # This assumes that the name appears at the top of the resume\n",
    "    # Usually, it might be in the first 5-7 words.\n",
    "    lines = text.split('\\n')\n",
    "    for line in lines[:5]:  # Look in the first few lines for the name\n",
    "        # Adjust the regex as needed to match typical name patterns\n",
    "        if re.match(r'^[A-Z][a-z]*\\s[A-Z][a-z]*', line):\n",
    "            return line.strip()\n",
    "    return \"Not Found\"\n",
    "\n",
    "# Function to extract the email address\n",
    "def extract_email(text):\n",
    "    email_pattern = r'[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}'\n",
    "    match = re.search(email_pattern, text)\n",
    "    return match.group(0) if match else \"Not Found\"\n",
    "\n",
    "# Function to extract the phone number\n",
    "def extract_phone_number(text):\n",
    "    # This regex pattern captures various phone number formats.\n",
    "    phone_pattern = r'\\b(?:\\+?(\\d{1,3}))?[-. (]*(\\d{3})[-. )]*(\\d{3})[-. ]*(\\d{4})\\b'\n",
    "    match = re.search(phone_pattern, text)\n",
    "    return match.group(0) if match else \"Not Found\"\n",
    "\n",
    "# Function to extract address (if address keywords like 'Address', 'Street' are present)\n",
    "def extract_address(text):\n",
    "    address_keywords = ['address', 'street', 'city', 'state', 'zip', 'postal']\n",
    "    lines = text.split('\\n')\n",
    "    address = \"Not Found\"\n",
    "    for line in lines:\n",
    "        if any(keyword in line.lower() for keyword in address_keywords):\n",
    "            address = line.strip()\n",
    "            break\n",
    "    return address\n",
    "\n",
    "# Function to process all PDFs in a folder and save the extracted info in a CSV\n",
    "def process_resumes(folder_path, output_csv_path):\n",
    "    data = []\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith('.pdf'):\n",
    "            pdf_path = os.path.join(folder_path, filename)\n",
    "            text = extract_text_from_pdf(pdf_path)\n",
    "            \n",
    "            # Extract information\n",
    "            name = extract_name(text)\n",
    "            email = extract_email(text)\n",
    "            phone = extract_phone_number(text)\n",
    "            address = extract_address(text)\n",
    "            \n",
    "            # Add extracted info to data list\n",
    "            data.append({\n",
    "                'File Name': filename,\n",
    "                'Name': name,\n",
    "                'Email': email,\n",
    "                'Phone': phone,\n",
    "                'Address': address\n",
    "            })\n",
    "    \n",
    "    # Create a DataFrame and save it to a CSV file\n",
    "    df = pd.DataFrame(data)\n",
    "    df.to_csv(output_csv_path, index=False)\n",
    "    print(f'Data saved to {output_csv_path}')\n",
    "\n",
    "# Example usage:\n",
    "# Replace 'path_to_resume_folder' with the actual folder path containing PDF resumes\n",
    "# Replace 'output.csv' with your desired output file name\n",
    "process_resumes('C:\\\\Users\\\\santhoshs.s\\\\jupyter\\\\resumes\\\\data\\\\data\\\\BPO\\\\bb', 'output.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c2ffa49-11dc-4dfe-991b-ff0976dcd3df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to output1.csv\n"
     ]
    }
   ],
   "source": [
    "import fitz  # PyMuPDF for reading PDFs\n",
    "import re\n",
    "import pandas as pd\n",
    "import os\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Function to extract text from PDF file\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    with fitz.open(pdf_path) as doc:\n",
    "        text = \"\"\n",
    "        for page in doc:\n",
    "            text += page.get_text()\n",
    "    return text\n",
    "\n",
    "# Function to extract the candidate's name\n",
    "def extract_name(text):\n",
    "    \"\"\"\n",
    "    Attempts to extract a name from the provided text using regular expressions and NER.\n",
    "\n",
    "    Args:\n",
    "        text (str): Text content to search for names.\n",
    "\n",
    "    Returns:\n",
    "        str: Extracted name (if found), or an empty string.\n",
    "    \"\"\"\n",
    "    # Try regular expressions first\n",
    "    name_patterns = [\n",
    "        r\"[A-Z][a-z]+ [A-Z][a-z]+\",  # Two words with capital letters (first name + last name)\n",
    "        r\"[A-Z][a-z]+-\\w+\"  # Hyphenated names like \"Anne-Marie\"\n",
    "    ]\n",
    "    \n",
    "    for pattern in name_patterns:\n",
    "        match = re.search(pattern, text)\n",
    "        if match:\n",
    "            return match.group()\n",
    "\n",
    "    # If regular expressions fail, try using NLTK for Named Entity Recognition (NER)\n",
    "    try:\n",
    "        tokens = word_tokenize(text)\n",
    "        tagged_text = nltk.pos_tag(tokens)\n",
    "        for word, tag in tagged_text:\n",
    "            if tag == 'NNP':  # Proper noun, typically used for names\n",
    "                return word\n",
    "    except LookupError:\n",
    "        print(\"NLTK data not downloaded. Install NLTK and run 'nltk.download()' to download required resources.\")\n",
    "\n",
    "    return \"Not Found\"\n",
    "\n",
    "# Function to extract the email address\n",
    "def extract_email(text):\n",
    "    email_pattern = r'[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}'\n",
    "    match = re.search(email_pattern, text)\n",
    "    return match.group(0) if match else \"Not Found\"\n",
    "\n",
    "# Function to extract the phone number\n",
    "def extract_phone_number(text):\n",
    "    # This regex pattern captures various phone number formats.\n",
    "    phone_pattern = r'\\b(?:\\+?(\\d{1,3}))?[-. (]*(\\d{3})[-. )]*(\\d{3})[-. ]*(\\d{4})\\b'\n",
    "    match = re.search(phone_pattern, text)\n",
    "    return match.group(0) if match else \"Not Found\"\n",
    "\n",
    "# Function to extract address (if address keywords like 'Address', 'Street' are present)\n",
    "def extract_address(text):\n",
    "    address_keywords = ['address', 'street', 'city', 'state', 'zip', 'postal']\n",
    "    lines = text.split('\\n')\n",
    "    address = \"Not Found\"\n",
    "    for line in lines:\n",
    "        if any(keyword in line.lower() for keyword in address_keywords):\n",
    "            address = line.strip()\n",
    "            break\n",
    "    return address\n",
    "\n",
    "# Function to process all PDFs in a folder and save the extracted info in a CSV\n",
    "def process_resumes(folder_path, output_csv_path):\n",
    "    data = []\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith('.pdf'):\n",
    "            pdf_path = os.path.join(folder_path, filename)\n",
    "            text = extract_text_from_pdf(pdf_path)\n",
    "            \n",
    "            # Extract information\n",
    "            name = extract_name(text)\n",
    "            email = extract_email(text)\n",
    "            phone = extract_phone_number(text)\n",
    "            address = extract_address(text)\n",
    "            \n",
    "            # Add extracted info to data list\n",
    "            data.append({\n",
    "                'File Name': filename,\n",
    "                'Name': name,\n",
    "                'Email': email,\n",
    "                'Phone': phone,\n",
    "                'Address': address\n",
    "            })\n",
    "    \n",
    "    # Create a DataFrame and save it to a CSV file\n",
    "    df = pd.DataFrame(data)\n",
    "    df.to_csv(output_csv_path, index=False)\n",
    "    print(f'Data saved to {output_csv_path}')\n",
    "\n",
    "# Example usage:\n",
    "# Replace 'path_to_resume_folder' with the actual folder path containing PDF resumes\n",
    "# Replace 'output.csv' with your desired output file name\n",
    "process_resumes('C:\\\\Users\\\\santhoshs.s\\\\jupyter\\\\resumes\\\\data\\\\data\\\\BPO\\\\bb', 'output1.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2084aec-81a1-4d8e-9941-fe2363ab5e03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to output2.csv\n"
     ]
    }
   ],
   "source": [
    "import fitz  # PyMuPDF for reading PDFs\n",
    "import re\n",
    "import pandas as pd\n",
    "import os\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Function to extract text from PDF file\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    with fitz.open(pdf_path) as doc:\n",
    "        text = \"\"\n",
    "        for page in doc:\n",
    "            text += page.get_text()\n",
    "    return text\n",
    "\n",
    "# Function to extract the candidate's name\n",
    "def extract_name(text):\n",
    "    name_patterns = [\n",
    "        r\"[A-Z][a-z]+ [A-Z][a-z]+\",  # Two words with capital letters (first name + last name)\n",
    "        r\"[A-Z][a-z]+-\\w+\"  # Hyphenated names like \"Anne-Marie\"\n",
    "    ]\n",
    "    \n",
    "    for pattern in name_patterns:\n",
    "        match = re.search(pattern, text)\n",
    "        if match:\n",
    "            return match.group()\n",
    "\n",
    "    # If regular expressions fail, try using NLTK for Named Entity Recognition (NER)\n",
    "    try:\n",
    "        tokens = word_tokenize(text)\n",
    "        tagged_text = nltk.pos_tag(tokens)\n",
    "        for word, tag in tagged_text:\n",
    "            if tag == 'NNP':  # Proper noun, typically used for names\n",
    "                return word\n",
    "    except LookupError:\n",
    "        print(\"NLTK data not downloaded. Install NLTK and run 'nltk.download()' to download required resources.\")\n",
    "\n",
    "    return \"Not Found\"\n",
    "\n",
    "# Function to extract the email address\n",
    "def extract_email(text):\n",
    "    email_pattern = r'[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}'\n",
    "    match = re.search(email_pattern, text)\n",
    "    return match.group(0) if match else \"Not Found\"\n",
    "\n",
    "# Function to extract the phone number\n",
    "def extract_phone_number(text):\n",
    "    phone_pattern = r'\\b(?:\\+?(\\d{1,3}))?[-. (]*(\\d{3})[-. )]*(\\d{3})[-. ]*(\\d{4})\\b'\n",
    "    match = re.search(phone_pattern, text)\n",
    "    return match.group(0) if match else \"Not Found\"\n",
    "\n",
    "# Function to extract address (if address keywords like 'Address', 'Street' are present)\n",
    "def extract_address(text):\n",
    "    address_keywords = ['address', 'street', 'city', 'state', 'zip', 'postal']\n",
    "    lines = text.split('\\n')\n",
    "    address = \"Not Found\"\n",
    "    for line in lines:\n",
    "        if any(keyword in line.lower() for keyword in address_keywords):\n",
    "            address = line.strip()\n",
    "            break\n",
    "    return address\n",
    "\n",
    "# Function to extract profile or summary\n",
    "def extract_profile(text):\n",
    "    profile_keywords = ['profile', 'summary', 'about me', 'professional summary']\n",
    "    profile = \"Not Found\"\n",
    "    lines = text.lower().split('\\n')\n",
    "    for i, line in enumerate(lines):\n",
    "        if any(keyword in line for keyword in profile_keywords):\n",
    "            profile = \"\\n\".join(lines[i:i+3]).strip()  # Get a few lines after the keyword\n",
    "            break\n",
    "    return profile\n",
    "\n",
    "# Function to extract links (e.g., LinkedIn, GitHub)\n",
    "def extract_links(text):\n",
    "    link_pattern = r'(https?://[^\\s]+)'\n",
    "    links = re.findall(link_pattern, text)\n",
    "    return ', '.join(links) if links else \"Not Found\"\n",
    "\n",
    "# Function to extract experience\n",
    "def extract_experience(text):\n",
    "    experience_keywords = ['experience', 'work history', 'professional experience']\n",
    "    experience = \"Not Found\"\n",
    "    lines = text.lower().split('\\n')\n",
    "    for i, line in enumerate(lines):\n",
    "        if any(keyword in line for keyword in experience_keywords):\n",
    "            experience = \"\\n\".join(lines[i:i+5]).strip()  # Get a few lines after the keyword\n",
    "            break\n",
    "    return experience\n",
    "\n",
    "# Function to extract education\n",
    "def extract_education(text):\n",
    "    education_keywords = ['education', 'academic background', 'qualifications']\n",
    "    education = \"Not Found\"\n",
    "    lines = text.lower().split('\\n')\n",
    "    for i, line in enumerate(lines):\n",
    "        if any(keyword in line for keyword in education_keywords):\n",
    "            education = \"\\n\".join(lines[i:i+5]).strip()  # Get a few lines after the keyword\n",
    "            break\n",
    "    return education\n",
    "\n",
    "# Function to extract languages\n",
    "def extract_languages(text):\n",
    "    language_keywords = ['languages', 'language proficiency']\n",
    "    languages = \"Not Found\"\n",
    "    lines = text.lower().split('\\n')\n",
    "    for i, line in enumerate(lines):\n",
    "        if any(keyword in line for keyword in language_keywords):\n",
    "            languages = \"\\n\".join(lines[i:i+3]).strip()  # Get a few lines after the keyword\n",
    "            break\n",
    "    return languages\n",
    "\n",
    "# Function to extract certificates\n",
    "def extract_certificates(text):\n",
    "    certificate_keywords = ['certification', 'certificate', 'licenses']\n",
    "    certificates = \"Not Found\"\n",
    "    lines = text.lower().split('\\n')\n",
    "    for i, line in enumerate(lines):\n",
    "        if any(keyword in line for keyword in certificate_keywords):\n",
    "            certificates = \"\\n\".join(lines[i:i+3]).strip()  # Get a few lines after the keyword\n",
    "            break\n",
    "    return certificates\n",
    "\n",
    "# Function to process all PDFs in a folder and save the extracted info in a CSV\n",
    "def process_resumes(folder_path, output_csv_path):\n",
    "    data = []\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith('.pdf'):\n",
    "            pdf_path = os.path.join(folder_path, filename)\n",
    "            text = extract_text_from_pdf(pdf_path)\n",
    "            \n",
    "            # Extract information\n",
    "            name = extract_name(text)\n",
    "            email = extract_email(text)\n",
    "            phone = extract_phone_number(text)\n",
    "            address = extract_address(text)\n",
    "            profile = extract_profile(text)\n",
    "            links = extract_links(text)\n",
    "            experience = extract_experience(text)\n",
    "            education = extract_education(text)\n",
    "            languages = extract_languages(text)\n",
    "            certificates = extract_certificates(text)\n",
    "            \n",
    "            # Add extracted info to data list\n",
    "            data.append({\n",
    "                'File Name': filename,\n",
    "                'Name': name,\n",
    "                'Email': email,\n",
    "                'Phone': phone,\n",
    "                'Address': address,\n",
    "                'Profile': profile,\n",
    "                'Links': links,\n",
    "                'Experience': experience,\n",
    "                'Education': education,\n",
    "                'Languages': languages,\n",
    "                'Certificates': certificates\n",
    "            })\n",
    "    \n",
    "    # Create a DataFrame and save it to a CSV file\n",
    "    df = pd.DataFrame(data)\n",
    "    df.to_csv(output_csv_path, index=False)\n",
    "    print(f'Data saved to {output_csv_path}')\n",
    "\n",
    "# Example usage:\n",
    "# Replace 'path_to_resume_folder' with the actual folder path containing PDF resumes\n",
    "# Replace 'output.csv' with your desired output file name\n",
    "process_resumes('C:\\\\Users\\\\santhoshs.s\\\\jupyter\\\\resumes\\\\data\\\\data\\\\BPO\\\\bb', 'output2.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b22d67-d1e3-423d-8867-abd93eebaaa4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
