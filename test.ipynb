{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyOtFdm0YVR0wQAASuaaFQ+p"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["!pip install PyPDF2\n","!pip install pdfplumber\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VnowFOO5LkJ5","executionInfo":{"status":"ok","timestamp":1729163629129,"user_tz":-330,"elapsed":7707,"user":{"displayName":"ds225229139 M.Sc. Data Science","userId":"17204601607049161067"}},"outputId":"3765a675-1211-4759-f4ac-43f4dea79878"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: PyPDF2 in /usr/local/lib/python3.10/dist-packages (3.0.1)\n","Collecting pdfplumber\n","  Downloading pdfplumber-0.11.4-py3-none-any.whl.metadata (41 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.0/42.0 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting pdfminer.six==20231228 (from pdfplumber)\n","  Downloading pdfminer.six-20231228-py3-none-any.whl.metadata (4.2 kB)\n","Requirement already satisfied: Pillow>=9.1 in /usr/local/lib/python3.10/dist-packages (from pdfplumber) (10.4.0)\n","Collecting pypdfium2>=4.18.0 (from pdfplumber)\n","  Downloading pypdfium2-4.30.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (48 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.5/48.5 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six==20231228->pdfplumber) (3.4.0)\n","Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six==20231228->pdfplumber) (43.0.1)\n","Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (1.17.1)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (2.22)\n","Downloading pdfplumber-0.11.4-py3-none-any.whl (59 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.2/59.2 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pdfminer.six-20231228-py3-none-any.whl (5.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m54.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pypdfium2-4.30.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m57.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: pypdfium2, pdfminer.six, pdfplumber\n","Successfully installed pdfminer.six-20231228 pdfplumber-0.11.4 pypdfium2-4.30.0\n"]}]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AN4AgSX5LA2J","executionInfo":{"status":"ok","timestamp":1729163688171,"user_tz":-330,"elapsed":59049,"user":{"displayName":"ds225229139 M.Sc. Data Science","userId":"17204601607049161067"}},"outputId":"55c497eb-412f-477a-cfc0-ff59ba86dec5"},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n"]},{"output_type":"stream","name":"stdout","text":["Please enter the file path of the resume (PDF): /content/Shree_Krishna_Kanth (1).pdf\n","\n","Objective not found in the resume.\n","Enter the job description: Good knowledge in python, sql\n","Resume is 10.05% similar to the job description.\n","The resume is suitable for the following job roles based on skill matches:\n","- Data Analyst: matched skills sql, tableau\n"]}],"source":["import pdfplumber\n","import re\n","from difflib import get_close_matches\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.metrics.pairwise import cosine_similarity\n","import nltk\n","from nltk.corpus import stopwords\n","from nltk.tokenize import word_tokenize\n","from nltk.stem import WordNetLemmatizer\n","\n","# Download NLTK resources\n","nltk.download('punkt')\n","nltk.download('stopwords')\n","nltk.download('wordnet')\n","\n","# Step 1: Create the dictionary with job roles as keys and skills as values\n","data = {\n","    'Software Engineer': 'Skilled in Python, machine learning, and web development with Django',\n","    'Backend Developer': 'Experience in Java, Spring Boot, and RESTful web services',\n","    'Data Analyst': 'Proficient in SQL, data analysis, and Tableau dashboards',\n","    'Frontend Developer': 'Expert in HTML, CSS, JavaScript, and React development',\n","    'AI/ML Engineer': 'Knowledge of deep learning, neural networks, and NLP tasks',\n","    'DevOps Engineer': 'Experienced in DevOps, Docker, Kubernetes, and cloud deployment'\n","}\n","\n","skill_keywords = [\n","    'python', 'java', 'machine learning', 'django', 'spring boot', 'sql',\n","    'data analysis', 'tableau', 'html', 'css', 'javascript', 'react',\n","    'nlp', 'neural networks', 'docker', 'kubernetes'\n","]\n","\n","# Step 2: Preprocess the text\n","def preprocess_text(text):\n","    text = text.lower()\n","    text = re.sub(r'[^a-zA-Z\\s]', '', text)  # Keep only letters and spaces\n","    return set(text.split())  # Convert to a set of words\n","\n","preprocessed_data = {role: preprocess_text(skills) for role, skills in data.items()}\n","\n","# Step 3: Extract text from PDF resume using pdfplumber\n","def extract_text_from_pdf(pdf_path):\n","    with pdfplumber.open(pdf_path) as pdf:\n","        text = \"\"\n","        for page in pdf.pages:\n","            text += page.extract_text() or \"\"  # Handle None if text extraction fails\n","    return text\n","\n","# Step 4: Extract the \"Objective\" section from the resume\n","def extract_objective(text):\n","    objective_regex = re.compile(r\"(objective|career objective)(.*?)(\\n[A-Z]|$)\", re.IGNORECASE | re.DOTALL)\n","    match = objective_regex.search(text)\n","    if match:\n","        return match.group(2).strip()  # Return the text between Objective and next section\n","    else:\n","        return None\n","\n","# Step 5: Extract skills from the resume text based on predefined keywords\n","def extract_skills_from_resume(resume_text):\n","    resume_text = preprocess_text(resume_text)  # Preprocess the text\n","    matched_skills = set()\n","    for skill in skill_keywords:\n","        if get_close_matches(skill, resume_text, n=1, cutoff=0.8):  # 80% similarity threshold\n","            matched_skills.add(skill)\n","    return matched_skills\n","\n","# Step 6: Match extracted skills to the job roles\n","def match_skills_to_roles(matched_skills):\n","    matching_roles = []\n","    for role, skills in preprocessed_data.items():\n","        matching_skills = matched_skills.intersection(skills)\n","        if len(matching_skills) >= 2:  # If two or more skills match, consider the role suitable\n","            matching_roles.append((role, matching_skills))\n","    return matching_roles\n","\n","# Step 7: Calculate Cosine Similarity\n","def calculate_similarity(resume_text, job_description):\n","    vectorizer = TfidfVectorizer()\n","    documents = [job_description, resume_text]\n","    tfidf_matrix = vectorizer.fit_transform(documents)\n","    cosine_sim = cosine_similarity(tfidf_matrix[0:1], tfidf_matrix[1:2])\n","    return cosine_sim[0][0] * 100  # Return similarity as percentage\n","\n","# Step 8: Main logic to analyze the PDF resume\n","def analyze_resume(pdf_path):\n","    # Extract the text from the PDF\n","    resume_text = extract_text_from_pdf(pdf_path)\n","\n","    # Extract the objective section\n","    objective_text = extract_objective(resume_text)\n","    if objective_text:\n","        print(\"Extracted Objective:\", objective_text)\n","    else:\n","        print(\"Objective not found in the resume.\")\n","\n","    # Define a job description for comparison (You can modify this)\n","    job_description = input(\"Enter the job description: \")\n","\n","    # Calculate similarity\n","    similarity_percentage = calculate_similarity(resume_text, job_description)\n","    print(f\"Resume is {similarity_percentage:.2f}% similar to the job description.\")\n","\n","    # Extract skills from the resume\n","    extracted_skills = extract_skills_from_resume(resume_text)\n","\n","    # Match the extracted skills to job roles\n","    matching_roles = match_skills_to_roles(extracted_skills)\n","\n","    # Print the results\n","    if matching_roles:\n","        print(\"The resume is suitable for the following job roles based on skill matches:\")\n","        for role, matched_skills in matching_roles:\n","            print(f\"- {role}: matched skills {', '.join(matched_skills)}\")\n","    else:\n","        print(\"No suitable job roles found based on the resume's skills.\")\n","\n","# Get PDF file path from user input\n","pdf_path = input(\"Please enter the file path of the resume (PDF): \")\n","print()\n","analyze_resume(pdf_path)\n"]},{"cell_type":"code","source":[],"metadata":{"id":"aNaOsU9mLnEV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"dcvklUEPMlSE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"s-d7C9XcMlOo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"BCZmregbMlLX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"kLWvsDEsMlIk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pdfplumber\n","import re\n","import pandas as pd\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import classification_report, accuracy_score\n","from sklearn.pipeline import make_pipeline\n","import nltk\n","from nltk.corpus import stopwords\n","from nltk.tokenize import word_tokenize\n","from nltk.stem import WordNetLemmatizer\n","\n","# Download NLTK resources\n","nltk.download('punkt')\n","nltk.download('stopwords')\n","nltk.download('wordnet')\n","\n","# Step 1: Prepare labeled dataset for job roles and skills\n","data = {\n","    'resume_text': [\n","        \"Skilled in Python, machine learning, and web development with Django.\",\n","        \"Experience in Java, Spring Boot, and RESTful web services.\",\n","        \"Proficient in SQL, data analysis, and Tableau dashboards.\",\n","        \"Expert in HTML, CSS, JavaScript, and React development.\",\n","        \"Knowledge of deep learning, neural networks, and NLP tasks.\",\n","        \"Experienced in DevOps, Docker, Kubernetes, and cloud deployment.\"\n","    ],\n","    'job_role': [\n","        'Software Engineer',\n","        'Backend Developer',\n","        'Data Analyst',\n","        'Frontend Developer',\n","        'AI/ML Engineer',\n","        'DevOps Engineer'\n","    ]\n","}\n","\n","# Convert to DataFrame\n","df = pd.DataFrame(data)\n","\n","# Step 2: Create the ML model\n","X = df['resume_text']\n","y = df['job_role']\n","\n","# Split the dataset into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# Create a pipeline that first vectorizes the text and then applies Logistic Regression\n","pipeline = make_pipeline(TfidfVectorizer(), LogisticRegression(max_iter=1000))\n","\n","# Train the model\n","pipeline.fit(X_train, y_train)\n","\n","# Step 3: Evaluate the model\n","y_pred = pipeline.predict(X_test)\n","print(classification_report(y_test, y_pred))\n","print(f'Accuracy: {accuracy_score(y_test, y_pred) * 100:.2f}%')\n","\n","# Step 4: Function to extract text from PDF resume using pdfplumber\n","def extract_text_from_pdf(pdf_path):\n","    with pdfplumber.open(pdf_path) as pdf:\n","        text = \"\"\n","        for page in pdf.pages:\n","            text += page.extract_text() or \"\"  # Handle None if text extraction fails\n","    return text\n","\n","# Step 5: Extract the \"Objective\" section from the resume\n","def extract_objective(text):\n","    objective_regex = re.compile(r\"(objective|career objective)(.*?)(\\n[A-Z]|$)\", re.IGNORECASE | re.DOTALL)\n","    match = objective_regex.search(text)\n","    if match:\n","        return match.group(2).strip()  # Return the text between Objective and next section\n","    else:\n","        return None\n","\n","# Step 6: Main logic to analyze the PDF resume\n","def analyze_resume(pdf_path):\n","    # Extract the text from the PDF\n","    resume_text = extract_text_from_pdf(pdf_path)\n","\n","    # Extract the objective section\n","    objective_text = extract_objective(resume_text)\n","    if objective_text:\n","        print(\"Extracted Objective:\", objective_text)\n","    else:\n","        print(\"Objective not found in the resume.\")\n","\n","    # Use the ML model to predict job role based on resume text\n","    predicted_role = pipeline.predict([resume_text])[0]\n","    print(f'The predicted job role for the resume is: {predicted_role}')\n","\n","# Get PDF file path from user input\n","pdf_path = input(\"Please enter the file path of the resume (PDF): \")\n","print()\n","analyze_resume(pdf_path)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iDhoyEDuMlGD","executionInfo":{"status":"ok","timestamp":1729163876284,"user_tz":-330,"elapsed":16624,"user":{"displayName":"ds225229139 M.Sc. Data Science","userId":"17204601607049161067"}},"outputId":"5c595b23-435e-4a5f-c5bd-2e6132010635"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"]},{"output_type":"stream","name":"stdout","text":["                    precision    recall  f1-score   support\n","\n"," Backend Developer       0.00      0.00      0.00       1.0\n","   DevOps Engineer       0.00      0.00      0.00       0.0\n","Frontend Developer       0.00      0.00      0.00       0.0\n"," Software Engineer       0.00      0.00      0.00       1.0\n","\n","          accuracy                           0.00       2.0\n","         macro avg       0.00      0.00      0.00       2.0\n","      weighted avg       0.00      0.00      0.00       2.0\n","\n","Accuracy: 0.00%\n","Please enter the file path of the resume (PDF): /content/Shree_Krishna_Kanth (1).pdf\n","\n","Objective not found in the resume.\n","The predicted job role for the resume is: Data Analyst\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"z1uyu1zyMpLN"},"execution_count":null,"outputs":[]}]}